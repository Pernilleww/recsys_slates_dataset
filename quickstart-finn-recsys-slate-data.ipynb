{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick start with the FINN.no recsys slate dataset [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/finn-no/recsys-slates-dataset/blob/master/quickstart-finn-recsys-slate-data.ipynb)\n",
    "\n",
    "This notebook gives an introduction to the dataset released with the paper [Dynamic Slate Recommendation with Gated Recurrent Units and Thompson Sampling](https://arxiv.org/abs/2104.15046). \n",
    "It is compatible with google colab, and can be run interactive by using the \"Open in Colab\"-button."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install dependencies, download and unzip data\n",
    "This step is necessary for google colab, not if you have manually downloaded the repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clone data repository..:\n",
      "Cloning into 'recsys-slates-dataset'...\n",
      "remote: Enumerating objects: 121, done.\u001b[K\n",
      "remote: Counting objects: 100% (121/121), done.\u001b[K\n",
      "remote: Compressing objects: 100% (84/84), done.\u001b[K\n",
      "remote: Total 121 (delta 57), reused 90 (delta 34), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (121/121), 844.46 KiB | 7.68 MiB/s, done.\n",
      "Resolving deltas: 100% (57/57), done.\n",
      "Filtering content: 100% (3/3), 1.30 GiB | 35.09 MiB/s, done.\n",
      "Unzip datafile..:\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get install git-lfs -q\n",
    "!git lfs install\n",
    "!echo Clone data repository..:\n",
    "!git clone https://github.com/finn-no/recsys-slates-dataset.git\n",
    "!echo Unzip datafile..:\n",
    "!gunzip -c recsys-slates-dataset/data/data.pt.gz >recsys-slates-dataset/data/data.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main dataset file `data.pt`\n",
    "The dataset consist of 2.2M unique users that have interacted up to 20 times with the internet platform platform, and has been exposed to up to 25 items at each interaction.\n",
    "`data.pt` contains all the slate and click data, and the two main arrays are `click` and `action`. \n",
    "The convention of the dimension of the arrays are that the first dimension is per user, second dimension is time and third dimension is the presented slate.\n",
    "The full description of all array are as follows:\n",
    "\n",
    "| Name        | Dimension           | Description  |\n",
    "| ------------- |:-------------:| -----:|\n",
    "| action      | [userId, interaction num, slate pos]| the presented slates to the users; |\n",
    "| click      | [userId, interaction num]      | items clicked by the users in each slate |\n",
    "| displayType      | [userId, interaction num]      | type of interaction the user had with the platform (search or recommendation) |\n",
    "| click_idx      | [userId, interaction num]      | Auxillary data: The position of the click in the `action` dataframe (integer from 0-24). <br> Useful for e.g. categorical likelihoods |\n",
    "| lengths      | [userId, interaction num]      | Auxillary data: the actual length of the slate. <br> Same as 25-`\"number of pad index in action\"` |\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dat = torch.load(\"recsys-slates-dataset/data/data.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userId : \t torch.Size([2277645])\nlengths : \t torch.Size([2277645, 20])\ndisplayType : \t torch.Size([2277645, 20])\naction : \t torch.Size([2277645, 20, 25])\nclick : \t torch.Size([2277645, 20])\nclick_idx : \t torch.Size([2277645, 20])\n"
     ]
    }
   ],
   "source": [
    "# Print dimensions of all arrays:\n",
    "for key, val in dat.items():\n",
    "  print(f\"{key} : \\t {val.size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: Get one interaction\n",
    "Get the presented slate + click for user 5 at interaction number 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slate:\ntensor([     1, 638995, 638947, 638711, 637590, 637930, 638894,      0,      0,\n             0,      0,      0,      0,      0,      0,      0,      0,      0,\n             0,      0,      0,      0,      0,      0,      0])\n \nClick:\ntensor(637590)\nType of interaction: (1 implies search, see ind2val file)\ntensor(1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Slate:\")\n",
    "print(dat['action'][5,3])\n",
    "print(\" \")\n",
    "print(\"Click:\")\n",
    "print(dat['click'][5,3])\n",
    "print(\"Type of interaction: (1 implies search, see ind2val file)\")\n",
    "print(dat['displayType'][5,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above extraction we can see that user 5 at interaction number 3 was presented with a total of 7 items: 6 \"real\" items and the \"no-click\" item that has index 1. The remaining positions in the array is padded with the index 0.\n",
    "The \"no-click\" item is always present in the slates, as the user has the alternative not to click on any of the presented items in the slate.\n",
    "Further, we see that the user clicked on the 4'th item in the slate.\n",
    "The slate length and the click position can be found by the following auxillary arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Click_idx:\ntensor(4)\nlengths:\ntensor(7)\n"
     ]
    }
   ],
   "source": [
    "print(\"Click_idx:\")\n",
    "print(dat['click_idx'][5,3])\n",
    "print(\"lengths:\")\n",
    "print(dat['lengths'][5,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index to item file `ind2val.pickle`\n",
    "This files contains mapping from indices to values for the attributes userId, itemId, category and displayType.\n",
    "\n",
    "| Name         | Length           | Description  |\n",
    "| -------------|:----:| -----:|\n",
    "| userId       | 1.3M | Scrambled id of users |\n",
    "| itemId       | 2.3M | Scrambled id of items. <br> First indicies disclose pad, noclick and unk items. |\n",
    "| category     | 290  | Mapping from the category index to a text string that describes the category. <br> The category value is a text string that describes the category and location of the group |\n",
    "| displayType  | 3    | Indices of whether the presented slate originated from search or recommendations|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example `ind2val`\n",
    "We print out the first elements of each index.\n",
    "For example, we see that category 3 is \"BAP,antiques,Trøndelag\" which implies the category contains antiques sold in the county of Trøndelag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \nitemId first entries:\n0: PAD\n1: noClick\n2: <UNK>\n3: item_3\n4: item_4\n \ncategory first entries:\n0: PAD\n1: noClick\n2: <UNK>\n3: BAP,antiques,Trøndelag\n4: MOTOR,,Sogn og Fjordane\n \ndisplayType first entries:\n1: search\n2: rec\n0: <UNK>\n \nuserId first entries:\n1: user_1\n2: user_2\n3: user_3\n4: user_4\n"
     ]
    }
   ],
   "source": [
    "ind2val = pickle.load(open(\"recsys-slates-dataset/data/ind2val.pickle\", \"rb\"))\n",
    "for key, val in ind2val.items():\n",
    "  print(\" \")\n",
    "  print(f\"{key} first entries:\")\n",
    "  for idx, name in val.items():\n",
    "    print(f\"{idx}: {val[idx]}\")\n",
    "    if idx >3:\n",
    "      break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item attributes file `itemattr.pickle`\n",
    "A small attribute file that provides two pieces of information on the items. These are stored as numpy arrays.\n",
    "\n",
    "| Name        | Dimension           | Description  |\n",
    "| ------------- |:-------------:| -----:|\n",
    "| category      | [itemId] | The group that each item belong to |\n",
    "| actions       | [itemId] | Auxillary data: count of the number of total exposures per item. <br> `-1` is used to pad special items (unk, pad,noclick) |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actions : (1311775,)\ncategory : (1311775,)\n\nThe full dictionary:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'actions': array([-1., -1., -1., ..., 39., 14.,  4.]),\n",
       " 'category': array([  0.,   1.,   2., ..., 289., 289., 289.])}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemattr = pickle.load(open(\"recsys-slates-dataset/data/itemattr.pickle\", \"rb\"))\n",
    "\n",
    "for key, val in itemattr.items():\n",
    "  print(f\"{key} : {val.shape}\")\n",
    "\n",
    "print(\"\\nThe full dictionary:\")\n",
    "itemattr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example `itemattr`\n",
    "Get the category of the clicked item above (from user 5, interaction number 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find the itemId that were click by user 5 in interaction 3:\nitemId: [tensor(637590)]\n\nFind the category index of that item in itemattr:\nCategory index: [135.]\n\nFinally, find the category name by using ind2val:\nCategory name: REAL_ESTATE,,Oppland\n"
     ]
    }
   ],
   "source": [
    "print(\"Find the itemId that were click by user 5 in interaction 3:\")\n",
    "itemId = [dat['click'][5,3]]\n",
    "print(f\"itemId: {itemId}\")\n",
    "\n",
    "print(\"\\nFind the category index of that item in itemattr:\")\n",
    "cat_idx = itemattr['category'][itemId]\n",
    "print(f\"Category index: {cat_idx}\")\n",
    "\n",
    "print(\"\\nFinally, find the category name by using ind2val:\")\n",
    "cat_name = ind2val['category'][cat_idx.item()]\n",
    "print(f\"Category name: {cat_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print some statistics about the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of no clicks: 0.24\n",
      "Average slate length: 11.14\n",
      "Ratio of slates that are recommendations: 0.303\n",
      "Average number of interactions per user: 16.43\n"
     ]
    }
   ],
   "source": [
    "print(f\"Ratio of no clicks: {(dat['click']==1).sum() / (dat['click']!=0).sum():.2f}\")\n",
    "print(f\"Average slate length: {(dat['lengths'][dat['lengths']!=0]).float().mean():.2f}\")\n",
    "print(f\"Ratio of slates that are recommendations: {(dat['displayType']==2).sum() / (dat['displayType']!=0).sum():.3f}\")\n",
    "print(f\"Average number of interactions per user: {(dat['click']!=0).sum(-1).float().mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directly load Pytorch Dataloaders with train/valid/test split\n",
    "It is possible to directly load the dataset as a pytorch dataloader which includes the same dataset splits etc as in the original paper.\n",
    "Use the `load_dataloaders` function in the `dataset.py` file. It has the following options:\n",
    "\n",
    "| Argument       | Description  |\n",
    "| ------------- |-----:|\n",
    "| batch_size       | Number of unique users sampled in each batch |\n",
    "| split_trainvalid | Ratio of full dataset dedicated to train <br> (val/test is split evenly among the rest) |\n",
    "| t_testsplit       | For users in valid and test, <br> how many interactions should belong to training set |\n",
    "| sample_uniform_action | If this is True, the exposures in the dataset <br> are sampled as in the `all-item likelihood` (see paper) |\n",
    "\n",
    "The outputs of the function is the same `ind2val` and `itemattr` as above.\n",
    "It also returns a dictionary with all the dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-27 18:25:55,179 Load data..\n",
      "2021-05-27 18:26:01,887 Loading dataset with action size=torch.Size([2277645, 20, 25]) and uniform candidate sampling=False\n",
      "2021-05-27 18:26:02,651 In train: num_users: 2277645, num_batches: 76\n",
      "2021-05-27 18:26:02,651 In valid: num_users: 113882, num_batches: 4\n",
      "2021-05-27 18:26:02,651 In test: num_users: 113882, num_batches: 4\n",
      " \n",
      "Dictionary containing the dataloaders:\n",
      "{'train': <torch.utils.data.dataloader.DataLoader object at 0x7fe7c0631b50>, 'valid': <torch.utils.data.dataloader.DataLoader object at 0x7fe7c0631c40>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7fe7c06315b0>}\n"
     ]
    }
   ],
   "source": [
    "import dataset\n",
    "ind2val, itemattr, dataloaders = dataset.load_dataloaders(\"recsys-slates-dataset/data\",\n",
    "                     batch_size=30000,\n",
    "                     split_trainvalid=0.9,\n",
    "                     t_testsplit = 5,\n",
    "                     sample_uniform_action=False)\n",
    "print(\" \")\n",
    "print(\"Dictionary containing the dataloaders:\")\n",
    "print(dataloaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userId torch.Size([30000])\nlengths torch.Size([30000, 20])\ndisplayType torch.Size([30000, 20])\naction torch.Size([30000, 20, 25])\nclick torch.Size([30000, 20])\nclick_idx torch.Size([30000, 20])\nmask_type torch.Size([30000, 20])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(dataloaders['train']))\n",
    "for key, val in batch.items():\n",
    "    print(key, val.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masking of train/test/val\n",
    "Each batch returns a dictionary of pytorch tensors with data, and contains the usual data fields described above.\n",
    "In addition, it contains a `mask_type` tensor which explains whether each click belongs to _train_, _valid_ or _test_.\n",
    "It is of the same dimensionality as the click tensor (`num users * num interactions`).\n",
    "This is because we want to return the full sequence of interactions so that e.g. the test set can use the first clicks of the user (which belongs to the training set) to build a user profile.\n",
    "The mask is defined in the following way:\n",
    "\n",
    "```\n",
    "mask2split = {\n",
    "    0 : 'PAD',\n",
    "    1 : 'train',\n",
    "    2 : 'valid',\n",
    "    3 : 'test'\n",
    "}\n",
    "```\n",
    "If the mask equals zero it means that the length of the user sequence was shorter than this index.\n",
    "The modeler has to take care to not train on elements in the validation or test dataset.\n",
    "Typically this can be done by masking all losses that does not originate from the training dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        ...,\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mask = (batch['mask_type']==1)\n",
    "train_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, for user number 1 in this batch, the first five interactions belong to the training set, and the remaining belongs to the validation set.\n",
    "We can extract the clicks that belong to the training set by using `mask_type`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask of user 2:\ntensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n \nClicks belonging to the training set:\ntensor([True, True, True, True, True, True, True, True, True, True, True, True,\n        True, True, True, True, True, True, True, True])\n \nSelect only the clicks in training dataset:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([  73296,   66666, 1154594,  613719,  642978, 1231978, 1231727,       1,\n",
       "          56397,       0,       0,       0,       0,       0,       0,       0,\n",
       "              0,       0,       0,       0])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Mask of user 2:\")\n",
    "print(batch['mask_type'][1,])\n",
    "print(\" \")\n",
    "print(\"Clicks belonging to the training set:\")\n",
    "print(train_mask[1,])\n",
    "print(\" \")\n",
    "print(\"Select only the clicks in training dataset:\")\n",
    "batch['click'][1,][train_mask[1,]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python388jvsc74a57bd0b64057e63add2b45b1ffc7eab9b09c8889b419c878e2fdf0d08f837f0fc857a7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
