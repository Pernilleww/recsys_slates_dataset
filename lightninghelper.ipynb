{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp lightning_helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lightning_helper\n",
    "\n",
    "> Helper functions for training models using the pytorch-lightning framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import recsys_slates_dataset.dataset_torch as dataset_torch\n",
    "import recsys_slates_dataset.datahelper as datahelper\n",
    "import pytorch_lightning as pl\n",
    "import logging\n",
    "class SlateDataModule(pl.LightningDataModule):\n",
    "    \"\"\"\n",
    "    A LightningDataModule wrapper around the dataloaders created in dataset_torch.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_dir= \"dat\",\n",
    "        batch_size=1024,\n",
    "        num_workers= 0,\n",
    "        sample_uniform_slate=False,\n",
    "        valid_pct= 0.05,\n",
    "        test_pct= 0.05,\n",
    "        t_testsplit= 5, *args, **kwargs):\n",
    "\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers =num_workers\n",
    "        self.sample_uniform_slate=sample_uniform_slate\n",
    "        self.valid_pct=valid_pct\n",
    "        self.test_pct=test_pct\n",
    "        self.t_testsplit=t_testsplit\n",
    "    def prepare_data(self):\n",
    "        \"\"\" \n",
    "        Download data to disk if not already downloaded.\n",
    "        \"\"\"\n",
    "        datahelper.download_data_files(data_dir=self.data_dir)\n",
    "\n",
    "    def setup(self, stage=None, num_negative_queries=0):\n",
    "\n",
    "        logging.info('Load data..')\n",
    "        self.ind2val, self.attributes, self.dataloaders = dataset_torch.load_dataloaders(\n",
    "            data_dir= self.data_dir,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers= self.num_workers,\n",
    "            sample_uniform_slate=self.sample_uniform_slate,\n",
    "            valid_pct= self.valid_pct,\n",
    "            test_pct= self.test_pct,\n",
    "            t_testsplit= self.t_testsplit)\n",
    "\n",
    "        \n",
    "        # Add some descriptive stats to the dataset as variables for easy access later:\n",
    "        self.num_items = self.train_dataloader().dataset.data['slate'].max().item()+1\n",
    "        _ , self.num_interactions, self.maxlen_slate = self.train_dataloader().dataset.data['slate'].size()\n",
    "        self.num_users = self.train_dataloader().dataset.data['userId'].max().item()+1\n",
    "        self.num_interaction_types = len(self.ind2val['interaction_type'])\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return self.dataloaders[\"train\"]\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return self.dataloaders[\"valid\"]\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return self.dataloaders[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "2021-07-06 08:46:02,891 Downloading data.npz\n",
      "2021-07-06 08:46:02,892 Downloading ind2val.json\n",
      "2021-07-06 08:46:02,893 Downloading itemattr.npz\n",
      "2021-07-06 08:46:02,893 Done downloading all files.\n",
      "2021-07-06 08:46:02,894 Load data..\n",
      "2021-07-06 08:46:02,894 Download data if not in data folder..\n",
      "2021-07-06 08:46:02,895 Downloading data.npz\n",
      "2021-07-06 08:46:02,895 Downloading ind2val.json\n",
      "2021-07-06 08:46:02,896 Downloading itemattr.npz\n",
      "2021-07-06 08:46:02,896 Done downloading all files.\n",
      "2021-07-06 08:46:02,897 Load data..\n",
      "2021-07-06 08:46:24,423 Loading dataset with slate size=torch.Size([2277645, 20, 25]) and uniform candidate sampling=False\n",
      "2021-07-06 08:46:24,510 In train: num_users: 2277645, num_batches: 2225\n",
      "2021-07-06 08:46:24,511 In valid: num_users: 113882, num_batches: 112\n",
      "2021-07-06 08:46:24,511 In test: num_users: 113882, num_batches: 112\n"
     ]
    }
   ],
   "source": [
    "# slow\n",
    "# Test that data is loaded\n",
    "dm = SlateDataModule()\n",
    "dm.prepare_data()\n",
    "dm.setup()\n",
    "\n",
    "checksum = next(iter(dm.train_dataloader()))['slate'].sum().item()\n",
    "assert checksum == 98897096275, \"Data error: Checksum of first batch is not expected value. Seed error?\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('tensorflow2': conda)",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
