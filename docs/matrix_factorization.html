---

title: Matrix Factorization example [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/finn-no/recsys-slates-dataset/blob/master/matrix_factorization.ipynb)


keywords: fastai
sidebar: home_sidebar



nb_path: "examples/matrix_factorization.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: examples/matrix_factorization.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">pytorch_lightning</span> <span class="k">as</span> <span class="nn">pl</span>

<span class="c1"># Define parameters for this run in a dictionary</span>
<span class="n">param</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;dim&#39;</span> <span class="p">:</span> <span class="mi">9</span><span class="p">,</span>
    <span class="s1">&#39;batch_size&#39;</span> <span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="mf">1e5</span><span class="p">),</span>
    <span class="s1">&#39;effective_batch_size&#39;</span> <span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="mf">2e6</span><span class="p">),</span>
    <span class="s1">&#39;sample_uniform_slates&#39;</span> <span class="p">:</span> <span class="kc">True</span><span class="p">,</span> <span class="c1"># If true, </span>
    <span class="s1">&#39;num_epochs&#39;</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span>
    <span class="s1">&#39;overfit_batches&#39;</span> <span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
    <span class="s1">&#39;name&#39;</span> <span class="p">:</span> <span class="s1">&#39;MatrixFactorization-CategoricalLoss&#39;</span>
    <span class="p">}</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="n">os</span><span class="o">.</span><span class="n">chdir</span><span class="p">(</span><span class="s2">&quot;/home/finn/tensorflow/personal-scratch/recsys_slates_dataset/examples/&quot;</span><span class="p">)</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;../../recsys_slates_dataset&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">recsys_slates_dataset</span> <span class="kn">import</span> <span class="n">lightning_helper</span>
<span class="n">dm</span> <span class="o">=</span> <span class="n">lightning_helper</span><span class="o">.</span><span class="n">SlateDataModule</span><span class="p">(</span><span class="n">num_workers</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="o">**</span><span class="n">param</span><span class="p">)</span>
<span class="n">dm</span><span class="o">.</span><span class="n">setup</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>2021-08-11 10:45:51,792 Load data..
2021-08-11 10:45:51,793 Download data if not in data folder..
2021-08-11 10:45:51,795 Downloading data.npz
2021-08-11 10:45:51,795 Downloading ind2val.json
2021-08-11 10:45:51,796 Downloading itemattr.npz
2021-08-11 10:45:51,797 Done downloading all files.
2021-08-11 10:45:51,798 Load data..
2021-08-11 10:46:24,414 Loading dataset with slate size=torch.Size([2277645, 20, 25]) and uniform candidate sampling=False
2021-08-11 10:46:25,089 Loading dataset with slate size=torch.Size([2277645, 20, 25]) and uniform candidate sampling=False
2021-08-11 10:46:25,104 Loading dataset with slate size=torch.Size([113882, 20, 25]) and uniform candidate sampling=False
2021-08-11 10:46:25,124 Loading dataset with slate size=torch.Size([113882, 20, 25]) and uniform candidate sampling=False
2021-08-11 10:46:25,126 In train: num_users: 2277645, num_batches: 23
2021-08-11 10:46:25,127 In valid: num_users: 113882, num_batches: 2
2021-08-11 10:46:25,128 In test: num_users: 113882, num_batches: 2
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Matrix-Factorization-Model">Matrix Factorization Model<a class="anchor-link" href="#Matrix-Factorization-Model"> </a></h2><p>We implement a simple Matrix Factorization model using categorical losses (instead of the traditional Gaussian loss).
Given a slate $S$ shown to the user $u$, the likelihood of clicking a specific item $c$ is:</p>
$$ \frac{e^{z_u *v_c}}{\sum_{i \in S} e^{z_u *v_c}} $$<p></p>
<p>where 
$z_u$ is a parameter vector for user $u$,<br>
$v_i$ is a parameter vector for item $i$,<br>
and $x*y$ is the inner product between $x$ and $y$.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.distributions</span> <span class="k">as</span> <span class="nn">dist</span>

<span class="k">class</span> <span class="nc">SimilarityDot</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="n">V</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">Z</span> <span class="o">*</span> <span class="n">V</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">dict_chunker</span><span class="p">(</span><span class="n">dict_of_seqs</span><span class="p">,</span> <span class="n">size</span><span class="p">):</span>
    <span class="s2">&quot;Iterates over the first dimension of a dict of sequences&quot;</span>
    <span class="n">length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dict_of_seqs</span><span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="n">dict_of_seqs</span><span class="o">.</span><span class="n">keys</span><span class="p">())[</span><span class="mi">0</span><span class="p">]])</span> <span class="c1"># length of first idex</span>
    <span class="k">return</span> <span class="p">(</span> <span class="p">{</span><span class="n">key</span> <span class="p">:</span> <span class="n">seq</span><span class="p">[</span><span class="n">pos</span><span class="p">:</span><span class="n">pos</span> <span class="o">+</span> <span class="n">size</span><span class="p">]</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">seq</span> <span class="ow">in</span> <span class="n">dict_of_seqs</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span> <span class="k">for</span> <span class="n">pos</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">length</span><span class="p">,</span> <span class="n">size</span><span class="p">))</span>

<span class="k">class</span> <span class="nc">MatrixFactorization</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> 
        <span class="n">num_users</span><span class="p">,</span> 
        <span class="n">num_items</span><span class="p">,</span>
        <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> 
        <span class="n">lr_start</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span>
        <span class="n">optim</span><span class="o">=</span><span class="s2">&quot;adam&quot;</span><span class="p">,</span>
        <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">()</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">score_func</span> <span class="o">=</span> <span class="n">SimilarityDot</span><span class="p">()</span>
        
        <span class="c1"># Initialize parameters</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">itemvec</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hparams</span><span class="o">.</span><span class="n">num_items</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hparams</span><span class="o">.</span><span class="n">dim</span><span class="p">)</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">itemvec</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">a</span><span class="o">=-</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">uservec</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hparams</span><span class="o">.</span><span class="n">num_users</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hparams</span><span class="o">.</span><span class="n">dim</span><span class="p">)</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">uservec</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">a</span><span class="o">=-</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">loglik</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
        <span class="c1"># Get user and item parameters:</span>
        <span class="c1"># Dimensions of tensors: [user/batch, interaction/step, item/slate, dim]</span>
        <span class="n">zetas</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">uservec</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="s1">&#39;userId&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">v_action</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">itemvec</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="s1">&#39;slate&#39;</span><span class="p">])</span>

        <span class="c1"># Compute the similarity (dot product) between the users and items for all items in all slates:</span>
        <span class="n">scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">score_func</span><span class="p">(</span><span class="n">zetas</span><span class="p">,</span><span class="n">v_action</span><span class="p">)</span>

        <span class="c1"># Set effectively zero probability for special Ids (0 is pad and 2 is UNK).</span>
        <span class="c1"># These scores are log, so -100 is effectively 0: exp(-100)=4e-44</span>
        <span class="n">scores</span><span class="p">[(</span><span class="n">batch</span><span class="p">[</span><span class="s1">&#39;slate&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="s1">&#39;slate&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">100</span>

        <span class="c1"># Flatten all Tensors to [user, slatelength]</span>
        <span class="c1"># This simplifies the computation of the loss</span>

        <span class="n">mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="s1">&#39;phase_mask&#39;</span><span class="p">]</span><span class="o">*</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="s1">&#39;click&#39;</span><span class="p">]</span><span class="o">&gt;</span><span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">bool</span><span class="p">()</span>
        <span class="n">scores_flat</span> <span class="o">=</span> <span class="n">scores</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span>
        <span class="n">click_idx_flat</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s1">&#39;click_idx&#39;</span><span class="p">][</span><span class="n">mask</span><span class="p">]</span>

        <span class="c1"># Compute the log likelihood of the observations:</span>
        <span class="c1"># We use a categorical loss</span>
        <span class="n">loglik</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">Categorical</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">scores_flat</span><span class="p">)</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">click_idx_flat</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">loglik</span>
    
    <span class="c1">#  TRAINING FUNCTIONS</span>
    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">phase</span><span class="p">):</span>
        <span class="n">stats</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="n">stats</span><span class="p">[</span><span class="s1">&#39;loglik&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loglik</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
        
        <span class="c1"># Since we are doing stochastic gradient decsent, </span>
        <span class="c1"># multiply with the data factor to get estimate of the loss for the whole dataset:</span>
        <span class="n">data_factor</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hparams</span><span class="o">.</span><span class="n">num_users</span> <span class="o">/</span> <span class="n">batch</span><span class="p">[</span><span class="s1">&#39;click&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
        <span class="n">stats</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span><span class="n">stats</span><span class="p">[</span><span class="s1">&#39;loglik&#39;</span><span class="p">]</span><span class="o">*</span><span class="n">data_factor</span><span class="p">)</span>

        <span class="c1"># Report loss and loglik:</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">stats</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">phase</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">val</span><span class="p">,</span> <span class="n">on_step</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">on_epoch</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sync_dist</span><span class="o">=</span> <span class="p">(</span><span class="n">phase</span><span class="o">!=</span><span class="s2">&quot;train&quot;</span><span class="p">))</span>
        
        <span class="k">return</span> <span class="n">stats</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span>

    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">validation_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">outputs</span><span class="p">):</span>
        <span class="c1"># Report mean absolute values of parameters:</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">par</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;param/</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">-L1&quot;</span><span class="p">,</span> <span class="n">par</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">on_step</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">sync_dist</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">phase</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">validation_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">phase</span><span class="o">=</span><span class="s2">&quot;valid&quot;</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">pars</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span><span class="n">pars</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">hparams</span><span class="o">.</span><span class="n">lr_start</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">optimizer</span>

    <span class="c1"># PREDICT FUNCTIONS BELOW HERE</span>
    <span class="nd">@torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">export</span>
    <span class="k">def</span> <span class="nf">forward_items</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> 
        <span class="n">batch</span> <span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> 
        <span class="n">targets</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
        <span class="n">t_rec</span><span class="p">:</span> <span class="nb">int</span><span class="o">=-</span><span class="mi">1</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; </span>
<span class="sd">        Given a batch of data, estimate scores for all items in target.</span>
<span class="sd">        If target is None, use all items.</span>
<span class="sd">        NB: This function is very memory intensive. Need small batch sizes.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="n">targets</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">targets</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hparams</span><span class="o">.</span><span class="n">num_items</span><span class="p">,</span><span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="n">target_vecs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">itemvec</span><span class="p">(</span><span class="n">targets</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">zetas</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">uservec</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="s1">&#39;userId&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">score_func</span><span class="p">(</span><span class="n">zetas</span><span class="p">,</span><span class="n">target_vecs</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">scores</span>

    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">recommend_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">num_rec</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">chunksize</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">t_rec</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">topk</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="s1">&#39;click&#39;</span><span class="p">]),</span> <span class="n">num_rec</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">batch_chunk</span> <span class="ow">in</span> <span class="n">dict_chunker</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">chunksize</span><span class="p">):</span>
            <span class="n">pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward_items</span><span class="p">(</span><span class="n">batch</span><span class="o">=</span><span class="n">batch</span><span class="p">,</span> <span class="n">t_rec</span><span class="o">=</span><span class="n">t_rec</span><span class="p">)</span>
            <span class="n">vals</span><span class="p">,</span> <span class="n">topk_chunk</span> <span class="o">=</span> <span class="n">pred</span><span class="p">[:,</span><span class="mi">3</span><span class="p">:]</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="n">num_rec</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">topk_chunk</span> <span class="o">=</span> <span class="mi">3</span><span class="o">+</span><span class="n">topk_chunk</span>

            <span class="n">topk</span><span class="p">[</span><span class="n">i</span><span class="p">:(</span><span class="n">i</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">pred</span><span class="p">))]</span> <span class="o">=</span> <span class="n">topk_chunk</span>
            <span class="n">i</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">topk</span>


<span class="n">model</span> <span class="o">=</span> <span class="n">MatrixFactorization</span><span class="p">(</span><span class="n">num_items</span> <span class="o">=</span> <span class="n">dm</span><span class="o">.</span><span class="n">num_items</span><span class="p">,</span> <span class="n">num_users</span> <span class="o">=</span> <span class="n">dm</span><span class="o">.</span><span class="n">num_users</span><span class="p">,</span> <span class="o">**</span><span class="n">param</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">checkpoint_callback</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">ModelCheckpoint</span><span class="p">(</span>
    <span class="n">monitor</span><span class="o">=</span><span class="s2">&quot;valid/loglik&quot;</span><span class="p">,</span>
    <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;max&quot;</span>
<span class="p">)</span>
<span class="n">cb</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">checkpoint_callback</span><span class="p">,</span>
    <span class="c1"># pl.callbacks.LearningRateMonitor(),</span>
    <span class="n">lightning_helper</span><span class="o">.</span><span class="n">CallbackPrintRecommendedCategory</span><span class="p">(</span><span class="n">dm</span><span class="p">)</span>
<span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">trainer</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span>
    <span class="n">overfit_batches</span><span class="o">=</span><span class="n">param</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;overfit_batches&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">),</span> <span class="c1"># for fast dry-runs</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="n">cb</span><span class="p">,</span>
    <span class="n">logger</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">loggers</span><span class="o">.</span><span class="n">TensorBoardLogger</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;logs&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">param</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">]),</span>
    <span class="n">max_epochs</span><span class="o">=</span><span class="n">param</span><span class="p">[</span><span class="s1">&#39;num_epochs&#39;</span><span class="p">],</span> 
    <span class="n">gpus</span><span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> 
    <span class="n">accumulate_grad_batches</span><span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">param</span><span class="p">[</span><span class="s1">&#39;effective_batch_size&#39;</span><span class="p">]</span><span class="o">/</span><span class="n">param</span><span class="p">[</span><span class="s1">&#39;batch_size&#39;</span><span class="p">]),</span> 
    <span class="n">weights_summary</span><span class="o">=</span><span class="s1">&#39;full&#39;</span><span class="p">,</span>
    <span class="p">)</span>

<span class="c1">#%% TRAIN</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dm</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
/opt/conda/envs/pytorch/lib/python3.8/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.
  rank_zero_deprecation(
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name       | Type          | Params
---------------------------------------------
0 | score_func | SimilarityDot | 0     
1 | itemvec    | Embedding     | 11.8 M
2 | uservec    | Embedding     | 20.5 M
---------------------------------------------
32.3 M    Trainable params
0         Non-trainable params
32.3 M    Total params
129.222   Total estimated model params size (MB)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

