{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp dataset_torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset_torch\n",
    "\n",
    "> Module to load the slates dataset into a Pytorch Dataset and Dataloaders with default train/valid test splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "import recsys_slates_dataset.datahelper as datahelper\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s %(message)s', level='INFO')\n",
    "\n",
    "class SequentialDataset(Dataset):\n",
    "    '''\n",
    "    '''\n",
    "    def __init__(self, data, sample_uniform_slate=False):\n",
    "\n",
    "        self.data = data\n",
    "        self.num_items = self.data['slate'].max()+1\n",
    "        self.sample_uniform_slate = sample_uniform_slate\n",
    "        self.mask2ind = {'train' : 1, 'valid' : 2, 'test' : 3}\n",
    "        \n",
    "        logging.info(\n",
    "            \"Loading dataset with slate size={} and uniform candidate sampling={}\"\n",
    "            .format(self.data['slate'].size(), self.sample_uniform_slate))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch = {key: val[idx] for key, val in self.data.items()}\n",
    "\n",
    "        if self.sample_uniform_slate:\n",
    "            # Sample actions uniformly:\n",
    "            action = torch.randint_like(batch['slate'], low=3, high=self.num_items)\n",
    "            \n",
    "            # Add noclick action at pos0 \n",
    "            # and the actual click action at pos 1 (unless noclick):\n",
    "            action[:,0] = 1\n",
    "            clicked = batch['click']!=1\n",
    "            action[:,1][clicked] = batch['click'][clicked]\n",
    "            batch['slate'] = action\n",
    "            # Set click idx to 0 if noclick, and 1 otherwise:\n",
    "            batch['click_idx'] = clicked.long()\n",
    "            \n",
    "        return batch\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data['click'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def load_dataloaders(data_dir= \"dat\",\n",
    "                     batch_size=1024,\n",
    "                     num_workers= 0,\n",
    "                     sample_uniform_slate=False,\n",
    "                     valid_pct= 0.05,\n",
    "                     test_pct= 0.05,\n",
    "                     t_testsplit= 5):\n",
    "    \"\"\"\n",
    "    Loads pytorch dataloaders to be used in training. If used with standard settings, the train/val/test split is equivalent to Eide et. al. 2021 \n",
    "    \"\"\"\n",
    "    \n",
    "    logging.info(\"Download data if not in data folder..\")\n",
    "    datahelper.download_data_files(data_dir=data_dir)\n",
    "\n",
    "    logging.info('Load data..')\n",
    "    with np.load(\"{}/data.npz\".format(data_dir)) as data_np:\n",
    "        data = {key: torch.tensor(val) for key, val in data_np.items()}\n",
    "    dataset = SequentialDataset(data, sample_uniform_slate)\n",
    "    \n",
    "    with open('{}/ind2val.json'.format(data_dir), 'rb') as handle:\n",
    "        # Use string2int object_hook found here: https://stackoverflow.com/a/54112705\n",
    "        ind2val = json.load(\n",
    "            handle, \n",
    "            object_hook=lambda d: {\n",
    "                int(k) if k.lstrip('-').isdigit() else k: v \n",
    "                for k, v in d.items()\n",
    "                }\n",
    "            )\n",
    "\n",
    "    num_users = len(data['click'])\n",
    "    num_validusers = int(num_users * valid_pct)\n",
    "    num_testusers = int(num_users * test_pct)\n",
    "    torch.manual_seed(0)\n",
    "    perm_user = torch.randperm(num_users)\n",
    "    valid_user_idx = perm_user[:num_validusers]\n",
    "    test_user_idx  = perm_user[num_validusers:(num_validusers+num_testusers)]\n",
    "    train_user_idx = perm_user[(num_validusers+num_testusers):]\n",
    "\n",
    "    # Split dictionary into train/valid/test with a phase mask that shows which interactions are in different sets \n",
    "    # (as some users have both train and valid data)\n",
    "    data_train = data\n",
    "    data_train['phase_mask'] = torch.ones_like(data['click']).bool()\n",
    "    data_train['phase_mask'][test_user_idx,t_testsplit:]=False\n",
    "    data_train['phase_mask'][valid_user_idx,t_testsplit:]=False\n",
    "\n",
    "    data_valid = {key: val[valid_user_idx] for key, val in data.items()}\n",
    "    data_valid['phase_mask'] = torch.zeros_like(data_valid['click']).bool()\n",
    "    data_valid['phase_mask'][:,t_testsplit:] = True\n",
    "\n",
    "    data_test = {key: val[test_user_idx] for key, val in data.items()}\n",
    "    data_test['phase_mask'] = torch.zeros_like(data_test['click']).bool()\n",
    "    data_test['phase_mask'][:,t_testsplit:] = True\n",
    "\n",
    "    data_dicts = {\n",
    "        \"train\" : data_train,\n",
    "        \"valid\" : data_valid,\n",
    "        \"test\" : data_test}\n",
    "\n",
    "    datasets = {\n",
    "        phase : SequentialDataset(data, sample_uniform_slate) \n",
    "        for phase, data in data_dicts.items()\n",
    "        }\n",
    "    \n",
    "\n",
    "    # Build dataloaders for each data subset:\n",
    "    dataloaders = {\n",
    "        phase: DataLoader(ds, batch_size=batch_size, shuffle=(phase==\"train\"), num_workers=num_workers)\n",
    "        for phase, ds in datasets.items()\n",
    "    }\n",
    "    for key, dl in dataloaders.items():\n",
    "        logging.info(\n",
    "            \"In {}: num_users: {}, num_batches: {}\".format(key, len(dl.dataset), len(dl))\n",
    "        )\n",
    "    \n",
    "    # Load item attributes:\n",
    "    with np.load('{}/itemattr.npz'.format(data_dir), mmap_mode=None) as itemattr_file:\n",
    "        itemattr = {key : val for key, val in itemattr_file.items()}\n",
    "\n",
    "    return ind2val, itemattr, dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-06 11:32:16,835 Download data if not in data folder..\n",
      "2021-07-06 11:32:16,835 Downloading data.npz\n",
      "2021-07-06 11:32:16,836 Downloading ind2val.json\n",
      "2021-07-06 11:32:16,836 Downloading itemattr.npz\n",
      "2021-07-06 11:32:16,837 Done downloading all files.\n",
      "2021-07-06 11:32:16,838 Load data..\n"
     ]
    }
   ],
   "source": [
    "#slow\n",
    "ind2val, itemattr, dataloaders = load_dataloaders()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('pytorch': conda)",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
